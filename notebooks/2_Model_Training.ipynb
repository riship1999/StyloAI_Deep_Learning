{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion Recommendation Model Training ðŸŽ¯\n",
    "\n",
    "This notebook covers:\n",
    "1. Collaborative Filtering Model\n",
    "2. Content-Based Filtering\n",
    "3. Deep Learning Model\n",
    "4. Hybrid Model Integration\n",
    "5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load preprocessed data\n",
    "X_train = np.load('../data/X_train.npy')\n",
    "X_test = np.load('../data/X_test.npy')\n",
    "y_train = np.load('../data/y_train.npy')\n",
    "y_test = np.load('../data/y_test.npy')\n",
    "\n",
    "print(\"Data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Collaborative Filtering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class CollaborativeFilter:\n",
    "    def __init__(self, n_factors=100):\n",
    "        self.n_factors = n_factors\n",
    "        \n",
    "    def fit(self, ratings_matrix):\n",
    "        # Perform SVD\n",
    "        U, sigma, Vt = np.linalg.svd(ratings_matrix, full_matrices=False)\n",
    "        \n",
    "        # Keep only top n_factors\n",
    "        self.user_features = U[:, :self.n_factors] @ np.diag(np.sqrt(sigma[:self.n_factors]))\n",
    "        self.item_features = np.diag(np.sqrt(sigma[:self.n_factors])) @ Vt[:self.n_factors, :]\n",
    "        \n",
    "    def predict(self, user_id, item_id):\n",
    "        return self.user_features[user_id] @ self.item_features[:, item_id]\n",
    "\n",
    "# Create and train collaborative filter\n",
    "cf_model = CollaborativeFilter(n_factors=50)\n",
    "# Assuming we have a ratings matrix\n",
    "ratings_matrix = np.random.rand(100, 1000)  # Example matrix\n",
    "cf_model.fit(ratings_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class ContentBasedFilter:\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer(stop_words='english')\n",
    "        \n",
    "    def fit(self, item_descriptions):\n",
    "        self.feature_matrix = self.tfidf.fit_transform(item_descriptions)\n",
    "        self.similarity_matrix = cosine_similarity(self.feature_matrix)\n",
    "        \n",
    "    def recommend(self, item_id, n_recommendations=5):\n",
    "        item_similarities = self.similarity_matrix[item_id]\n",
    "        similar_items = np.argsort(item_similarities)[::-1][1:n_recommendations+1]\n",
    "        return similar_items\n",
    "\n",
    "# Create and train content-based filter\n",
    "cb_model = ContentBasedFilter()\n",
    "# Assuming we have item descriptions\n",
    "descriptions = [\"Sample description\"] * 1000  # Example descriptions\n",
    "cb_model.fit(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class FashionNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, output_size=50):\n",
    "        super(FashionNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, hidden_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size//2, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "\n",
    "# Create dataloader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize model\n",
    "model = FashionNet(input_size=X_train.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 10\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    losses.append(epoch_loss/len(train_loader))\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, Loss: {losses[-1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hybrid Model Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class HybridRecommender:\n",
    "    def __init__(self, cf_weight=0.4, cb_weight=0.3, dl_weight=0.3):\n",
    "        self.cf_weight = cf_weight\n",
    "        self.cb_weight = cb_weight\n",
    "        self.dl_weight = dl_weight\n",
    "        \n",
    "    def recommend(self, user_id, item_id):\n",
    "        # Get predictions from each model\n",
    "        cf_pred = cf_model.predict(user_id, item_id)\n",
    "        cb_pred = cb_model.recommend(item_id)[0]  # Get top recommendation\n",
    "        dl_pred = model(torch.FloatTensor(X_test[item_id])).detach().numpy()\n",
    "        \n",
    "        # Combine predictions\n",
    "        hybrid_pred = (\n",
    "            self.cf_weight * cf_pred +\n",
    "            self.cb_weight * cb_pred +\n",
    "            self.dl_weight * dl_pred\n",
    "        )\n",
    "        \n",
    "        return hybrid_pred\n",
    "\n",
    "# Create hybrid recommender\n",
    "hybrid_model = HybridRecommender()\n",
    "\n",
    "# Example recommendation\n",
    "user_id, item_id = 0, 0\n",
    "prediction = hybrid_model.recommend(user_id, item_id)\n",
    "print(f\"Hybrid prediction for user {user_id}, item {item_id}: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def evaluate_models():\n",
    "    # Prepare test data\n",
    "    test_users = np.random.randint(0, 100, size=1000)\n",
    "    test_items = np.random.randint(0, 1000, size=1000)\n",
    "    \n",
    "    # Get predictions\n",
    "    hybrid_preds = []\n",
    "    for user, item in zip(test_users, test_items):\n",
    "        pred = hybrid_model.recommend(user, item)\n",
    "        hybrid_preds.append(pred)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'mae': np.mean(np.abs(np.array(hybrid_preds) - y_test[:1000])),\n",
    "        'rmse': np.sqrt(np.mean((np.array(hybrid_preds) - y_test[:1000])**2))\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Evaluate models\n",
    "metrics = evaluate_models()\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric.upper()}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save models\n",
    "import joblib\n",
    "\n",
    "# Save collaborative filtering model\n",
    "joblib.dump(cf_model, '../models/cf_model.joblib')\n",
    "\n",
    "# Save content-based model\n",
    "joblib.dump(cb_model, '../models/cb_model.joblib')\n",
    "\n",
    "# Save deep learning model\n",
    "torch.save(model.state_dict(), '../models/dl_model.pth')\n",
    "\n",
    "# Save hybrid model\n",
    "joblib.dump(hybrid_model, '../models/hybrid_model.joblib')\n",
    "\n",
    "print(\"All models saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
